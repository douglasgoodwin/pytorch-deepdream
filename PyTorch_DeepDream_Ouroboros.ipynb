{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DeepDream Ouroboros loop with PyTorch\n",
        "\n",
        "All you need to do is clone a git repository, change into its directory, and run the main script.\n",
        "\n",
        "![](https://www.evernote.com/shard/s51/sh/afa51254-c0b9-4071-ac1c-3d82cef714da/xkMEW32dm5Z8E_T8hLEOLa8fnKaWsCB76O5UFxVfuHzbVWeTDksqrLp6Lg/deep/0/image.png)"
      ],
      "metadata": {
        "id": "fcIRZs2h5zG4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wE6lzhxR5lkf",
        "outputId": "f524082e-ba96-4a03-e47d-42f192453e0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch-deepdream'...\n",
            "remote: Enumerating objects: 497, done.\u001b[K\n",
            "remote: Counting objects: 100% (160/160), done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 497 (delta 125), reused 116 (delta 116), pack-reused 337\u001b[K\n",
            "Receiving objects: 100% (497/497), 44.48 MiB | 15.86 MiB/s, done.\n",
            "Resolving deltas: 100% (257/257), done.\n"
          ]
        }
      ],
      "source": [
        "# clone the repository\n",
        "!git clone https://github.com/douglasgoodwin/pytorch-deepdream.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ./pytorch-deepdream"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3K6UPUwR93RQ",
        "outputId": "a4466f42-25b0-43f9-c1bb-a6f57b7709a7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pytorch-deepdream\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ouroboros Video Examples\n",
        "\n",
        "Here are some further examples that you can create using this code!\n",
        "\n",
        "The idea here is that whatever the network dreams just feed that back to it's input and apply a geometric transformation.\n",
        "\n",
        "### Ouroboros: Zoom transform\n",
        "\n",
        "If we apply only central zoom we get this:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/douglasgoodwin/pytorch-deepdream/master/data/examples/ouroboros/zoom.gif\" />\n",
        "\n",
        "### Ouroboros: Zoom and Rotation transforms\n",
        "\n",
        "Applying central zoom and at the same time applying a 3 degree rotation per frame yields this:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/douglasgoodwin/pytorch-deepdream/master/data/examples/ouroboros/zoom_rotate.gif\" />\n",
        "\n",
        "### Ouroboros: Translation\n",
        "\n",
        "Finally if we do a simple translation (5 px per frame top left to bottom right direction):\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/douglasgoodwin/pytorch-deepdream/master/data/examples/ouroboros/translation.gif\" />\n",
        "\n",
        "Hopefully these did not break your brain - it feels like web 1.0 early 2000s. Bear with me."
      ],
      "metadata": {
        "id": "ItV3OLfQBL48"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example!"
      ],
      "metadata": {
        "id": "FokYYp66-QEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python deepdream.py \\\n",
        " --use_noise \\\n",
        " --create_ouroboros \\\n",
        " --ouroboros_length 48 --fps 24 \\\n",
        " --frame_transform ZOOM_ROTATE \\\n",
        " --layers_to_use relu3_3 \\\n",
        " --img_width 640"
      ],
      "metadata": {
        "id": "QdyZMBg398Fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use your options\n",
        "\n",
        "\n",
        "## Here are the options and arguments:\n",
        "\n",
        "```\n",
        "usage: deepdream.py [-h] [--input INPUT] [--img_width IMG_WIDTH]\n",
        "                    [--layers_to_use LAYERS_TO_USE [LAYERS_TO_USE ...]]\n",
        "                    [--model_name {VGG16,VGG16_EXPERIMENTAL,GOOGLENET,RESNET50,ALEXNET}]\n",
        "                    [--pretrained_weights {IMAGENET,PLACES_365}]\n",
        "                    [--pyramid_size PYRAMID_SIZE]\n",
        "                    [--pyramid_ratio PYRAMID_RATIO]\n",
        "                    [--num_gradient_ascent_iterations NUM_GRADIENT_ASCENT_ITERATIONS]\n",
        "                    [--lr LR] [--create_ouroboros]\n",
        "                    [--ouroboros_length OUROBOROS_LENGTH] [--fps FPS]\n",
        "                    [--frame_transform {ZOOM,ZOOM_ROTATE,TRANSLATE}]\n",
        "                    [--blend BLEND] [--should_display]\n",
        "                    [--spatial_shift_size SPATIAL_SHIFT_SIZE]\n",
        "                    [--smoothing_coefficient SMOOTHING_COEFFICIENT]\n",
        "                    [--use_noise]\n",
        "\n",
        "options:\n",
        "  -h, --help            show this help message and exit\n",
        "  --input INPUT         Input IMAGE or VIDEO name that will be used for\n",
        "                        dreaming\n",
        "  --img_width IMG_WIDTH\n",
        "                        Resize input image to this width\n",
        "  --layers_to_use LAYERS_TO_USE [LAYERS_TO_USE ...]\n",
        "                        Layer whose activations we should maximize while\n",
        "                        dreaming\n",
        "  --model_name {VGG16,VGG16_EXPERIMENTAL,GOOGLENET,RESNET50,ALEXNET}\n",
        "                        Neural network (model) to use for dreaming\n",
        "  --pretrained_weights {IMAGENET,PLACES_365}\n",
        "                        Pretrained weights to use for the above model\n",
        "  --pyramid_size PYRAMID_SIZE\n",
        "                        Number of images in an image pyramid\n",
        "  --pyramid_ratio PYRAMID_RATIO\n",
        "                        Ratio of image sizes in the pyramid\n",
        "  --num_gradient_ascent_iterations NUM_GRADIENT_ASCENT_ITERATIONS\n",
        "                        Number of gradient ascent iterations\n",
        "  --lr LR               Learning rate i.e. step size in gradient ascent\n",
        "  --create_ouroboros    Create Ouroboros video (default False)\n",
        "  --ouroboros_length OUROBOROS_LENGTH\n",
        "                        Number of video frames in ouroboros video\n",
        "  --fps FPS             Number of frames per second\n",
        "  --frame_transform {ZOOM,ZOOM_ROTATE,TRANSLATE}\n",
        "                        Transform used to transform the output frame and feed\n",
        "                        it back to the network input\n",
        "  --blend BLEND         Blend coefficient for video creation\n",
        "  --should_display      Display intermediate dreaming results (default False)\n",
        "  --spatial_shift_size SPATIAL_SHIFT_SIZE\n",
        "                        Number of pixels to randomly shift image before grad\n",
        "                        ascent\n",
        "  --smoothing_coefficient SMOOTHING_COEFFICIENT\n",
        "```"
      ],
      "metadata": {
        "id": "L1zd13ob-Bzy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Where are the images?\n",
        "\n",
        "![](https://www.evernote.com/shard/s51/sh/a274fc72-2b00-451a-8318-c059d025e10a/7ynChbd9f71rV1n374jh0Q6ODlB5msN9uhY_EgIi63CBQxkQNuFDUDos4g/deep/0/image.png)"
      ],
      "metadata": {
        "id": "toviXC7w_r8z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NEjHWy8d_vVn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}